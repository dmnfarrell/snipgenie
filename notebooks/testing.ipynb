{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## snpgenie testing notebook\n",
    "\n",
    "Note: the current version of the M.bovis genome online has genes missing in the annotation. See https://www.ncbi.nlm.nih.gov/nuccore/LT708304.1?report=graph\n",
    "\n",
    "Updated files can be found here: https://github.com/dmnfarrell/gordon-group/tree/master/mbovis_annotation\n",
    "\n",
    "links:\n",
    "\n",
    "* https://github.com/JosephCrispell/GeneralTools/tree/master/ProcessingPipeline\n",
    "* [Woodchester Park eLife paper](https://elifesciences.org/articles/45833)\n",
    "* [An African origin for Mycobacterium bovis](https://academic.oup.com/emph/article/2020/1/49/5719036)\n",
    "* http://www.htslib.org/doc/bcftools.html\n",
    "* https://mtbgenomicsworkshop.readthedocs.io/\n",
    "* [BCFtools cheat sheet](https://gist.github.com/elowy01/93922762e131d7abd3c7e8e166a74a0b)\n",
    "* https://biopython.org/wiki/Category:Cookbook\n",
    "* https://pyvcf.readthedocs.io/en/v0.4.6/INTRO.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,shutil,subprocess\n",
    "import random\n",
    "import glob, time\n",
    "from importlib import reload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 200)\n",
    "import pylab as plt\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from gzip import open as gzopen\n",
    "sys.path.append('pathogenie')\n",
    "from snpgenie import tools, aligners, app, trees, plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mbovis samples from SRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sra = pd.read_csv('../sra_mbovis_runtable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get master table with Loiseau et al. meta data¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../Loiseau_TableS1.xlsx')\n",
    "master = pd.merge(df,sra,left_on='BIOSAMPLE',right_on='BioSample',how='inner')\n",
    "master.to_csv('../mbovis_sra_master.csv',index=False)\n",
    "cols = ['Run','CLONAL_COMPLEX','COUNTRY_ISOLATION','LibraryLayout','Host','ReleaseDate','Bytes','Bases','GENOME_COVERAGE']\n",
    "#master.columns\n",
    "#master.geo_loc_name_country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representative samples of lineages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub=master[(master.LibraryLayout=='PAIRED') & (master.COUNTRY_ISOLATION.notnull()) & (master.CLONAL_COMPLEX=='Eu2')]\n",
    "#print (sub[cols])\n",
    "#sub[cols].to_csv('../temp.csv')\n",
    "accessions=['SRR1792002','SRR5216872','SRR5486071','ERR841808','ERR125601',\n",
    "            'SRR8063654','SRR8063665','SRR8065079','SRR1791768','SRR1791960','ERR2815558']\n",
    "testset = master[master.Run.isin(accessions)]\n",
    "print (testset[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch from SRA\n",
    "def fetch_sra_reads(df,path):\n",
    "    \"\"\"download a subset of reads \"\"\"\n",
    "    \n",
    "    for i,r in df.iterrows():\n",
    "        files = glob.glob(os.path.join(path,r.Run+'*'))        \n",
    "        if len(files)==0:\n",
    "            cmd = 'fastq-dump --split-files {n} --outdir {o}'.format(n=r.Run,o=path)\n",
    "            print (cmd)\n",
    "            subprocess.check_output(cmd,shell=True)\n",
    "\n",
    "fetch_sra_reads(testset,path='/storage/btbgenie/mbovis_sra')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blasting to known contaminants\n",
    "\n",
    "* https://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-019-2684-x#Sec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unmapped reads from a bam file\n",
    "\n",
    "infile='mapped/3_S57_L001.bam'\n",
    "cmd = 'samtools view -b -f 4 {i} > unmapped.bam'.format(i=infile)\n",
    "print (cmd)\n",
    "#align with bwa to known index of contaminants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine FASTQ file quality and define trimming parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(tools)\n",
    "\n",
    "df = tools.fastq_to_dataframe(testfile)\n",
    "df.length.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_reads_default(filename, outfile, right_quality=30):\n",
    "    \"\"\"Trim adapters\"\"\"\n",
    "        \n",
    "    fastq_parser = SeqIO.parse(gzopen(filename, \"rt\"), \"fastq\")\n",
    "    c=0\n",
    "    out = gzopen(outfile, \"wt\")\n",
    "    for record in fastq_parser:\n",
    "        score = record.letter_annotations[\"phred_quality\"]         \n",
    "        for i in range(len(score)-1,0,-1):\n",
    "            if score[i] >= right_quality:\n",
    "                break\n",
    "        #trimmed.append(record[:i])\n",
    "        #print (record[:i])        \n",
    "        #c+=1\n",
    "        #if c>100:\n",
    "        #    break    \n",
    "        SeqIO.write(record[:i],out,'fastq')\n",
    "    return\n",
    "\n",
    "testfile = 'mbovis_sra/SRR1791711_1.fastq.gz'\n",
    "st=time.time()\n",
    "trim_reads_default(testfile,'trimmed.fastq.gz')\n",
    "print (time.time()-st)\n",
    "df = tools.fastq_to_dataframe('trimmed.fastq.gz')\n",
    "df.length.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiprocess trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_fastq(filename, chunks=4):\n",
    "    \"\"\"Split fastq file\"\"\"\n",
    "    \n",
    "    names=[]\n",
    "    tmp = '/tmp'\n",
    "    tmpfiles = []\n",
    "    record_iter = SeqIO.parse(gzopen(filename, \"rt\"), \"fastq\")\n",
    "    length = \n",
    "    for i, batch in enumerate(tools.batch_iterator(record_iter, chunksize)):\n",
    "        tempfile = \"group_%i.fastq\" % (i + 1)\n",
    "        tmpfiles.append(tempfile)\n",
    "        names.append(tempfile)\n",
    "        with open(tempfile, \"w\") as handle:\n",
    "            count = SeqIO.write(batch, handle, \"fastq\")\n",
    "        print(\"Wrote %i records to %s\" % (count, tempfile))\n",
    "    return names\n",
    "\n",
    "split_fastq(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.plot_fastq_qualities(testfile,limit=100000)\n",
    "plt.savefig('fastq_quals.png',dpi=100)\n",
    "tools.plot_fastq_gc_content(testfile, limit=50000)\n",
    "plt.savefig('gc.png',dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sample ids from fastq files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1='/storage/btbgenie/albania'\n",
    "files = glob.glob(os.path.join(path1,'*.fastq.gz'))\n",
    "path2='/storage/btbgenie/mbovis_sra'\n",
    "files = glob.glob(os.path.join(path2,'*.fastq.gz'))\n",
    "#add outgroup file\n",
    "#files.append\n",
    "files = app.get_files_from_paths([path1,path2])\n",
    "\n",
    "df = app.get_samples(files)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align the FASTQ files against reference and create VCF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(aligners)\n",
    "ref = app.mbovis_genome\n",
    "samples = app.get_samples(files)\n",
    "app.align_reads(samples, idx=ref, threads=10, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove duplicated reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'samtools rmdup A_reads.bt2.sorted.bam A_reads.bt2.sorted.noDups.bam'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping unmapped reads\n",
    "\n",
    "https://gist.github.com/davfre/8596159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## variant calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      1  434991  869981 1304971 1739962 2174952 2609942 3044933 3479923\n",
      " 3914913 4349904]\n",
      "parallel bcftools mpileup -r {1} -a \"AD,ADF,ADR,DP,SP,INFO/AD,INFO/ADF,INFO/ADR\" -O b  --min-MQ 60 -o {2} -f /home/damien/.config/snpgenie/genome/Mbovis_AF212297.fa mapped/ERR551704.bam mapped/6_S7_L001.bam mapped/3_S57_L001.bam ::: \"LT708304.1\":1-434990 \"LT708304.1\":434991-869980 \"LT708304.1\":869981-1304970 \"LT708304.1\":1304971-1739961 \"LT708304.1\":1739962-2174951 \"LT708304.1\":2174952-2609941 \"LT708304.1\":2609942-3044932 \"LT708304.1\":3044933-3479922 \"LT708304.1\":3479923-3914912 \"LT708304.1\":3914913-4349903 :::+ /tmp/1.bcf /tmp/434991.bcf /tmp/869981.bcf /tmp/1304971.bcf /tmp/1739962.bcf /tmp/2174952.bcf /tmp/2609942.bcf /tmp/3044933.bcf /tmp/3479923.bcf /tmp/3914913.bcf\n",
      "bcftools concat /tmp/1.bcf /tmp/434991.bcf /tmp/869981.bcf /tmp/1304971.bcf /tmp/1739962.bcf /tmp/2174952.bcf /tmp/2609942.bcf /tmp/3044933.bcf /tmp/3479923.bcf /tmp/3914913.bcf -O b -o mapped/raw.bcf\n",
      "bcftools call -V indels --ploidy 1 -m -v -o mapped/calls.vcf mapped/raw.bcf\n",
      "bcftools reheader --samples mapped/samples.txt -o /tmp/calls.vcf mapped/calls.vcf\n",
      "bcftools filter -i \"QUAL>=40 && FORMAT/DP>=30 && DP4>=4 && MQ>30\" -o mapped/filtered.vcf.gz -O z mapped/calls.vcf\n",
      "took 34.0 seconds\n",
      "33.57878375053406\n"
     ]
    }
   ],
   "source": [
    "reload(app)\n",
    "bam_files = glob.glob('mapped/*.bam')\n",
    "st=time.time()\n",
    "vcf_file = app.variant_calling(bam_files, ref, 'mapped', threads=10, overwrite=True)\n",
    "print (time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = vcf_to_dataframe('result.vcf')\n",
    "print (v1.var_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = vcf_to_dataframe('mapped/raw.bcf')\n",
    "print (v2.var_type.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filtering\n",
    "\n",
    "```\n",
    "FORMAT/AD   .. Allelic depth (Number=R,Type=Integer)\n",
    "FORMAT/ADF  .. Allelic depths on the forward strand (Number=R,Type=Integer)\n",
    "FORMAT/ADR  .. Allelic depths on the reverse strand (Number=R,Type=Integer)\n",
    "FORMAT/DP   .. Number of high-quality bases (Number=1,Type=Integer)\n",
    "FORMAT/SP   .. Phred-scaled strand bias P-value (Number=1,Type=Integer)\n",
    "FORMAT/SCR  .. Number of soft-clipped reads (Number=1,Type=Integer)\n",
    "\n",
    "INFO/AD     .. Total allelic depth (Number=R,Type=Integer)\n",
    "INFO/ADF    .. Total allelic depths on the forward strand (Number=R,Type=Integer)\n",
    "INFO/ADR    .. Total allelic depths on the reverse strand (Number=R,Type=Integer)\n",
    "INFO/SCR    .. Number of soft-clipped reads (Number=1,Type=Integer)\n",
    "\n",
    "FORMAT/DV   .. Deprecated in favor of FORMAT/AD; Number of high-quality non-reference bases, (Number=1,Type=Integer)\n",
    "FORMAT/DP4  .. Deprecated in favor of FORMAT/ADF and FORMAT/ADR; Number of high-quality ref-forward, ref-reverse,\n",
    "               alt-forward and alt-reverse bases (Number=4,Type=Integer)\n",
    "FORMAT/DPR  .. Deprecated in favor of FORMAT/AD; Number of high-quality bases for each observed allele (Number=R,Type=Integer)\n",
    "INFO/DPR    .. Deprecated in favor of INFO/AD; Number of high-quality bases for each observed allele (Number=R,Type=Integer)\n",
    "```\n",
    "\n",
    "Joe filters: DP - 30, DP4 - 4, MQ - 35, SUP - 0.95 and COV - 0.05. GQ and FQ = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcf\n",
    "vcf_reader = vcf.Reader(open('mapped/filtered.vcf.gz', 'rb')) \n",
    "for record in vcf_reader:\n",
    "    print (record)\n",
    "    for sample in record.samples:\n",
    "        print (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'bcftools filter -e \"QUAL<=40 && DP>=30 && DP4>=4 && MQ>=35\" -o filtered.vcf.gz -O z mapped/calls.vcf'\n",
    "print (cmd)\n",
    "tmp = subprocess.check_output(cmd,shell=True)\n",
    "v = vcf_to_dataframe('filtered.vcf.gz')\n",
    "v.var_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## consequence calling for vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(app)\n",
    "ref=app.ref_genome\n",
    "gff = '../pathogenie/data/Mbovis_csq_format.gff'\n",
    "out = 'csqout.tsv'\n",
    "def csq_call():\n",
    "    cmd = 'bcftools csq -f {r} -g {g} filtered.vcf.gz -Ot -o {o}'.format(r=ref,g=gff,o=out)\n",
    "    print (cmd)\n",
    "    tmp = subprocess.check_output(cmd,shell=True)\n",
    "    \n",
    "csq_call()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(app)\n",
    "def read_csq_file(filename):\n",
    "    cols = ['1','filename','2','chrom','start','snp_type','gene','locus_tag','strand','feature_type','aa','nuc',]\n",
    "    csqdf = pd.read_csv(filename,sep='[|\\t]',comment='#',names=cols, engine='python')\n",
    "    return csqdf\n",
    "csq = read_csq_file('csqout.tsv')\n",
    "csq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vcf_to_dataframe(vcf_file, quality=30):\n",
    "    \"\"\"Convert vcf to dataframe\"\"\"\n",
    "\n",
    "    import vcf\n",
    "    ext = os.path.splitext(vcf_file)[1]    \n",
    "    if ext == '.gz':\n",
    "        file = gzopen(vcf_file, \"rt\")\n",
    "    else:\n",
    "        file = open(vcf_file)\n",
    "    vcf_reader = vcf.Reader(file,'r')    \n",
    "    res=[]\n",
    "    cols = ['chrom','var_type','sub_type','start','end','REF','ALT','QUAL','DP']\n",
    "    i=0\n",
    "    for rec in vcf_reader:\n",
    "        #if i>10:\n",
    "        #    break\n",
    "        x = [rec.CHROM, rec.var_type, rec.var_subtype, rec.start, rec.end, rec.REF, str(rec.ALT[0]),\n",
    "            rec.QUAL, rec.INFO['DP']]\n",
    "        #print (rec.__dict__)\n",
    "        #print (rec.INFO.keys())\n",
    "        #for call in rec.samples:\n",
    "        #    print (call.sample, call.data, rec.genotype(call.sample)) \n",
    "        res.append(x)\n",
    "        #print (x)    \n",
    "        #i+=1\n",
    "    res = pd.DataFrame(res,columns=cols)    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = vcf_to_dataframe('mapped/filtered.vcf.gz')\n",
    "vdf.var_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make fasta alignment from filtered VCF sites with multiple samples\n",
    "\n",
    "https://github.com/JosephCrispell/GeneralTools/blob/master/ProcessingPipeline/CreateFastaWithReferenceFromFiltered_28-06-17.pl\n",
    "\n",
    "\"The allele frequencies at each position in the aligned (against reference) sequence from each isolate were examined. For a haploid organism these frequencies are expected to be either 0 or 1, with some random variation expected from sequencing errors (Sobkowiak et al., 2018). A heterozygous site was defined as one where the allele frequencies were >0.05 and <0.95. Four cattle-derived sequences that had more than 150 heterozygous sites, and allele frequencies that were clustered and non-random (data not shown), were removed. In addition, 26 badger-derived and 16 cattle-derived M. bovis sequences were removed because of suspected errors in the metadata (Appendix 1: Investigating isolate metadata discrepancies).\n",
    "\n",
    "For the sequences from the remaining isolates (204 badger- and 169 cattle-derived isolates), alleles were called at each variant position if they had mapping quality ≥30, high-quality base depth ≥4 (applied to reverse and forward reads separately), read depth ≥30, and allele support ≥0.95. For any site that failed these criteria, if the allele called had been observed in a different isolate that had passed, a second round of filtering was conducted using a high-quality base depth of 5 (total across forward and reverse reads) and the same allele support. As recombination is thought to be extremely rare for mycobacteria (Namouchi et al., 2012), variants in close proximity could indicate a region that is difficult to sequence or under high selection. To avoid calling variants in these regions, variant positions within 10 bp of one another were removed. Following filtering, sequences from 11 badger and 10 cattle isolates that had insufficient coverage (<95%) of the variant positions were removed. Once the alignment was generated, sites with a consistency index less than 1, generally considered homoplasies (Farris, 1989), were removed (n = 4, of 14,991 sites) using HomoplasyFinder (v0.0.0.9; Crispell et al., 2019; RRID: SCR_017300). All the scripts necessary for the processing of the WGS data are freely available online.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fasta_alignment_from_vcf(vcf_file):\n",
    "    \"\"\"Get site alt bases as sequences from all samples in a vcf file\"\"\"\n",
    "    \n",
    "    import vcf\n",
    "    from collections import defaultdict \n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'rb'))   \n",
    "    #print (vcf_reader.samples)\n",
    "    def default(): \n",
    "        return []\n",
    "    result = defaultdict(default)\n",
    "    sites = []\n",
    "    for record in vcf_reader:\n",
    "        ref = record.REF\n",
    "        result['ref'].append(record.REF)\n",
    "        sites.append(record.POS)\n",
    "        for sample in record.samples:\n",
    "            name = sample.sample\n",
    "            if sample.gt_bases != None:\n",
    "                result[name].append(sample.gt_bases)\n",
    "            else:\n",
    "                result[name].append(record.REF)           \n",
    "\n",
    "    recs = []\n",
    "    #sites_matrix = {}\n",
    "    for sample in result:\n",
    "        seq = ''.join(result[sample])\n",
    "        seqrec = SeqRecord(Seq(seq),id=sample)\n",
    "        recs.append(seqrec)\n",
    "        print (len(seqrec))\n",
    "        \n",
    "    smat = pd.DataFrame(result)\n",
    "    smat.index = sites        \n",
    "    return recs, smat\n",
    "\n",
    "seqrecs, smat = fasta_alignment_from_vcf2('mapped/filtered.vcf.gz')\n",
    "SeqIO.write(result, 'variants_new.fa', 'fasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "def site_proximity_filter(vcf_file, dist=10, outdir='mapped'):\n",
    "    \"\"\"Remove any pairs of sites within dist of each other\"\"\"\n",
    "\n",
    "    import vcf\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'rb'))\n",
    "    sites = [record.POS for record in vcf_reader]\n",
    "    #print (sites)\n",
    "    found = []\n",
    "    for i in range(len(sites)-1):\n",
    "        if sites[i+1] - sites[i] <= dist:\n",
    "            #print (sites[i], sites[i+1],'close')\n",
    "            found.extend([sites[i], sites[i+1]])\n",
    "    #print (found)\n",
    "    new = sorted(list(set(sites) - set(found)))\n",
    "    print ('proximity filter found %s/%s sites' %(len(new),len(sites)))\n",
    "    tempdir = tempfile.gettempdir()\n",
    "    out = os.path.join(outdir,'temp.vcf')\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'rb'))\n",
    "    vcf_writer = vcf.Writer(open(out, 'w'), vcf_reader)\n",
    "    for record in vcf_reader:\n",
    "        if record.POS in new:\n",
    "            #print (record)\n",
    "            vcf_writer.write_record(record)\n",
    "    vcf_writer.close()\n",
    "    #overwrite input vcf\n",
    "    bcftoolscmd = tools.get_cmd('bcftools')\n",
    "    cmd = 'bcftools view {o} -O z -o {gz}'.format(o=out,gz=vcf_file)\n",
    "    tmp = subprocess.check_output(cmd,shell=True)\n",
    "    return\n",
    "\n",
    "site_proximity_filter('mapped/filtered.vcf.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_multiprocess(inputs):\n",
    "    #split sites into chunks and run in parallel for long jobs\n",
    "    \n",
    "    import multiprocessing as mp\n",
    "    blocks = np.array_split(np.array(inputs),threads)\n",
    "    result=[]\n",
    "    funclist = []\n",
    "    pool = mp.Pool(threads)\n",
    "    for subset in blocks:            \n",
    "        f = pool.apply_async(worker_func, [subset])      \n",
    "        funclist.append(f)            \n",
    "    try:\n",
    "        for f in funclist:\n",
    "            out = f.get(timeout=None)               \n",
    "            if len(out)>0:\n",
    "                result.append(out)\n",
    "    except KeyboardInterrupt:\n",
    "        print ('process interrupted')\n",
    "        pool.terminate()\n",
    "        sys.exit(0)\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phylogeny from MSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RAXML(infile, name='variants', threads=8):\n",
    "    \"\"\"Run Raxml pthreads\"\"\"\n",
    "\n",
    "    bootstraps = 10\n",
    "    model = 'GTRCAT'\n",
    "    s1 = random.randint(0,1e8)\n",
    "    s2 = random.randint(0,1e8)\n",
    "    \n",
    "    files = glob.glob('RAxML_*')\n",
    "    for f in files:\n",
    "        os.remove(f)\n",
    "    cmd = 'raxmlHPC-PTHREADS -f a -N {nb} -T {t} -m {m} -V -p {s1} -x {s2} -n {n} -s {i}'.format(t=threads,nb=bootstraps,n=name,i=infile,s1=s1,s2=s2,m=model)\n",
    "    print (cmd)\n",
    "    tmp = subprocess.check_output(cmd, shell=True)\n",
    "    return\n",
    "    \n",
    "run_RAXML('variants.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(filename, labelmap=None):\n",
    "    \"\"\"Draw a tree \"\"\"\n",
    "    \n",
    "    from ete3 import Tree, NodeStyle, TreeStyle\n",
    "    t = Tree(filename)\n",
    "    t.set_outgroup('ref')    \n",
    "    if labelmap != None:\n",
    "        trees.set_tiplabels(t,labelmap)\n",
    "    trees.format_nodes(t)\n",
    "    ts = TreeStyle()\n",
    "    ts.scale=1000\n",
    "    t.render(\"%%inline\", tree_style=ts)\n",
    "    t.render(\"tree.png\", tree_style=ts)\n",
    "    return t\n",
    "\n",
    "sra['filename'] = sra.Run.apply(lambda x: 'mapped/'+x+'.bam')\n",
    "print (sra[:3])\n",
    "labelmap = dict(zip(sra.filename,sra.geo_loc_name_country))\n",
    "#print (labelmap)\n",
    "t = create_tree('RAxML_bipartitions.variants', labelmap)\n",
    "t.render(\"%%inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Phylo\n",
    "tree=Phylo.read('RAxML_bestTree.variants','newick')\n",
    "Phylo.draw(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csq gff format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.gff_bcftools_format('../snpgenie/data/Mbovis_AF212297.gb', '../Mbovis_csq_new.gff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gff=tools.gff_to_features('../pathogenie/data/Mbovis_AF212297.gff')\n",
    "g=tools.features_to_dataframe(gff)\n",
    "tools.features_summary(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(plotting)\n",
    "f,ax=plt.subplots(1,1,figsize=(12,3))\n",
    "st=time.time()\n",
    "plotting.plot_bam_alignment('../test_results/mapped/3_S57_L001.bam', 'LT708304.1', 2000, 3000, yend=100, rect_height=3, ax=ax)\n",
    "print (time.time()-st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features(rec, ax, rows=3, xstart=0, xend=30000):\n",
    "    \n",
    "    h=1\n",
    "    df = tools.records_to_dataframe([rec])    \n",
    "    df = df[(df.feat_type!='region') & (df['feat_type']!='source')]\n",
    "    df = df[(df.start>xstart) & (df.end<xend)]\n",
    "    df['length'] = df.end-df.start\n",
    "    y = list(range(1,rows)) * len(df)\n",
    "    df['y'] = y[:len(df)]\n",
    "    df['color'] = 'blue'\n",
    "    df = df.fillna('')\n",
    "    #print (df)  \n",
    "    \n",
    "    from matplotlib.collections import PatchCollection\n",
    "    import matplotlib.patches as mpatches\n",
    "\n",
    "    patches=[]\n",
    "    for i,r in df.iterrows():        \n",
    "        #rect = plt.Rectangle((r.start, r.y), r.length, h/2,\n",
    "        #                        alpha=.5, linewidth=.5,\n",
    "        #                        edgecolor='black', facecolor=r.color)\n",
    "        if r.strand == 1:\n",
    "            x = r.start\n",
    "            dx = r.length\n",
    "        else:\n",
    "            x = r.end\n",
    "            dx = -r.length\n",
    "        arrow = mpatches.Arrow(x, r.y, dx, 0, alpha=.7, width=.3, \n",
    "                               edgecolor='black')\n",
    "        txt = ax.text(r.start, r.y-h/2, r.gene, size=16)\n",
    "        patches.append(arrow)  \n",
    "        \n",
    "    ax.add_collection(PatchCollection(patches, match_original=True))  \n",
    "    ax.set_xlim(xstart, xend)\n",
    "    ax.set_ylim(.4,rows-.5)\n",
    "    plt.yticks([])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    def onclick(event):\n",
    "        print('%s click: button=%d, x=%d, y=%d, xdata=%f, ydata=%f' %\n",
    "              ('double' if event.dblclick else 'single', event.button,\n",
    "               event.x, event.y, event.xdata, event.ydata))\n",
    "        ax.text(event.x, event.y, 'HI!')\n",
    "        ax.figure.canvas.draw()\n",
    "    #cid = ax.figure.canvas.mpl_connect('button_press_event', onclick)\n",
    "    return\n",
    "\n",
    "reload(tools)\n",
    "recs = tools.gff_to_records(app.mbovis_gff)\n",
    "rec=recs[0]\n",
    "f,ax=plt.subplots(1,1,figsize=(15,1.5))\n",
    "plot_features(rec, ax=ax, xstart=26000,xend=35000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## replace pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chrom(bam_file):\n",
    "    \"\"\"Get first sequence name in a bam file\"\"\"\n",
    "\n",
    "    import pysam\n",
    "    samfile = pysam.AlignmentFile(bam_file, \"r\")\n",
    "    iter=samfile.fetch(start=0,end=10)\n",
    "    for read in iter:\n",
    "        if read.reference_name:\n",
    "            return read.reference_name\n",
    "        \n",
    "get_chrom('mapped/3_S57_L001.bam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bamnostic as bs\n",
    "bam = bs.AlignmentFile('mapped/3_S57_L001.bam', 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrom=bam.header['SQ'][0]['SN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, read in enumerate(bam.fetch(chrom, 1, 10)):\n",
    "    print(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coverage(bam_file, chr, start, end):\n",
    "    \"\"\"Get coverage from bam file at specified region\"\"\"\n",
    "    \n",
    "    import bamnostic as bs\n",
    "    if bam_file is None or not os.path.exists(bam_file):\n",
    "        return\n",
    "    bam = bs.AlignmentFile(bam_file, 'rb')\n",
    "    for i, read in enumerate(bam.fetch(chrom, 1, 10)):\n",
    "        print(read)\n",
    "    return\n",
    "\n",
    "get_coverage('mapped/3_S57_L001.bam', chrom, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def samtools_flagstats(filename):\n",
    "    \"\"\"Parse samtools flagstat output into dictionary\"\"\"\n",
    "    \n",
    "    cmd = 'samtools flagstat %s' %filename\n",
    "    tmp = subprocess.check_output(cmd, shell=True, universal_newlines=True)\n",
    "    x = tmp.split('\\n')    \n",
    "    x = [int(i.split('+')[0]) for i in x[:-1]]\n",
    "    #print (x)\n",
    "    cols = ['total','secondary','supplementary','duplicates','mapped',\n",
    "            'paired','read1','read2','properly paired','with itself','singletons']\n",
    "    d = {}\n",
    "    for c,v in zip(cols,x):\n",
    "        d[c] = v\n",
    "    return d\n",
    "\n",
    "samtools_flagstats('mapped/6_S7_L001.bam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
